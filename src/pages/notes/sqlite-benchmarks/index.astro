---
import Layout from '../../../layouts/layout.astro';
import { A, Note, Title, P, Info, C, H2, Code, H3 } from '../../../components';
import { notes } from '../../notes';
import { ResultsMac } from './results-mac';
import { Resultsx86 } from './results-linux-x86';
import { ResultsArm } from './results-linux-arm';

const info = notes['sqlite-benchmarks'];
---

<Layout>
	<Note>
		<Title subtitle={info.subtitle}>
			{info.title}
		</Title>
		<P>
			I have recently been on a path towards radical simplification of the systems I build. Forgoing
			Spring Boot for a simple Axum Rust backend is a simple choice for me. Choosing a database is
			an entirely different story. I have been using PostgreSQL successfully, but operating it has
			been a bit of a black box. Sure, I just spin up a standard docker container and it works, but
			I wouldn't want to start straying from the default configuration considering the absolute
			wealth of features and manual pages there are. So I started looking into SQLite.
		</P>
		<H2>Advantages</H2>
		<P>
			SQLite is an embedded database, a library if you will. Compared to dedicated DB servers that
			need to be operated separately, this simplifies the deployment significantly. Additionally,
			the latency of queries is extremly low, as they are more function call than networked request.
			For incremental backups, there is the excellent
			<A href="https://litestream.io/">Litestream</A> project that observes the write-ahead log and pushes
			changes up to an S3 compatible object storage.
			<em>Right up my alley</em>.
		</P>
		<H2>Performance</H2>
		<P>
			I conducted some microbenchmarks to gauge the performance of SQLite. There is one table that
			is declared as follows:
		</P>
		<Code
			value={`CREATE TABLE metrics(bucket TEXT NOT NULL, date TEXT NOT NULL, data TEXT NOT NULL);`}
		/>
		<P>
			You might notice that the motivating application to try SQLite is a home-grown metrics
			collection system. For one scenario I also add indices on <C>bucket</C> and <C>date</C>. Next,
			I ran a bunch of (hopefully) self explanatory scenarios and measured the execution time of the
			queries in isolation. Read queries are prepared statements of the form:
		</P>
		<Code value={`SELECT * FROM metrics WHERE bucket = ?1 AND rowid = ?2;`} />
		<P>
			Notice that <C>rowid</C> is an implicit column added by SQLite. Write queries:
		</P>
		<Code value={`INSERT INTO metrics (bucket, date, data) VALUES (?1, ?2, ?3);`} />
		<P>
			The benchmarks were run on my local macbook, as well as a linux ARM server and a linux x86
			server on Hetzner.
		</P>
		<H3>Results</H3>
		<ResultsMac />
		<ResultsArm />
		<Resultsx86 />
		<H3>Observations</H3>
		<P>
			Notice the increase of queries per second across the board once write-ahead log (WAL) mode is
			turned on and Synchronization is set to Normal. The 90th percentile duration column is
			indicated in microseconds! Even the slow queries are still incredibly fast. The most
			"real-world" scenario here is probably <C>WAL + Index (mixed, 80% read)</C>. We are looking at
			a QPS in the ballpark of <C>100'000</C> regardless of platform. Plenty fast for my usecases.
		</P>
		<H2>Limitations</H2>
		<P>
			I found it hard to get any speedup when trying to access a single SQLite DB from multiple
			threads. Writes are single threaded by nature, not much of a debate there, but reads (at least
			in WAL mode) should scale well. It's probably down to the library I use for connection
			pooling. But considering single threaded performance is already so good, I didn't spend to
			much time here. In Rust lingo, I just use an <C>Arc&ltMutex&ltConnection&gt&gt</C> to protect a
			single connection from concurrent access.
		</P>
	</Note>
</Layout>
